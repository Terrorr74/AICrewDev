# LLM Configuration for CrewAI
# Copy this file to .env and set your actual values

# LLM Provider (openai, anthropic, ollama, other)
LLM_PROVIDER=openai

# Model Names by Provider
# OpenAI: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
# Anthropic: claude-3-5-sonnet-20241022, claude-3-haiku-20240307, claude-3-opus-20240229
# Ollama: llama3.1:8b, llama3.1:70b, codellama:7b, mistral:7b
LLM_MODEL_NAME=gpt-4o-mini

# API Keys (set based on your provider)
# OpenAI API Key
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic API Key
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# Base URL (optional, for custom endpoints or Ollama)
LLM_BASE_URL=

# Model Parameters
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=4000
LLM_TIMEOUT=60
LLM_MAX_RETRIES=3
LLM_MAX_RPM=

# Streaming and Behavior
LLM_STREAMING=false
LLM_VERBOSE=true
LLM_RESPECT_CONTEXT_WINDOW=true

# CrewAI Specific Settings
CREWAI_TELEMETRY_OPT_OUT=true
